Задание:
1) взять "small"  набор данных для какой-нибудь предметной области с http://jmcauley.ucsd.edu/data/amazon/ (например про фильмы, но вообще по желанию). преобразовать полученный набор данных: оставить только текст отзыва, оценку бинаризовать (>3 и <=3). Почитать про предобработку текстов (нормализация, стемминг, лемматизация, удаление пунктации и стоп слов). Подумать какие шаги предобработки будут полезны для следующего пункта задания, применить их. Применить к текстам извлекатор признаков tf-idf, Получить  2 набора данных: вектора необработанных тектсов + оценка и вектора обработанных + оценка. Разбить их на обучающую и тестовую выборки (в обоих наборах в обе выборки должно попасть одно и то же)
jmcauley.ucsd.edu
Amazon review data
2) Цель второго пункта — понять, какой классификатор над этими данными лучший и над какими признаками. Сравнивать будем разные логистические регрессии. Задача — по тексту предсказывать оценку. Собственно надо обучить 4 различные лог регрессии: простая над 2 полученными выборками и с L2 регуляризацией над 2 полученными выборками.  Выбрать метрику качества, по которой будем сравниваться. Для каждого классификатора провести подбор гиперпараметров (например коэффициент регуляризации, веса классов, если выборка несбалансирована, оптимизатор, коэффициенты отбрасывания примеров у tf-idf). Сравнить полученные лучшие классификаторы, сказать какой лучший и протестировать его тестовой выборке. Самая важная часть этого пункта — понять методику тестирования и выбора наилучшей модели. Стоит читать про крос валидацию и активно спрашивать меня
3*) Пункт необязательный,  если будет интересно. У тебя еще не было мат статистики, поэтому будет сложно. Сравнить 4 лучших классификатора из пункта 2 не просто на глаз, вроде у этого больше качество, а честно — применить статестический критерий и сравнить распределние выборок точностей. Почитать про знаковый критерий (или еще какой) и применить его
